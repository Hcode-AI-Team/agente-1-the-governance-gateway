# ============================================================================
# Configura√ß√µes de Seguran√ßa (Safety Settings) - Vertex AI
# ============================================================================
# Define os n√≠veis de bloqueio para conte√∫do potencialmente prejudicial
# que o modelo pode gerar ou processar.
#
# üìö NOTA PEDAG√ìGICA - Contexto do Curso:
#
# ‚ö†Ô∏è Aula 01 - Por que este arquivo existe mas n√£o √© usado:
# Na Aula 01, focamos em FinOps e estrutura ADK. Usamos simula√ß√£o de LLM
# (sem chamadas reais ao Vertex AI), ent√£o safety_settings n√£o s√£o aplicadas.
# O arquivo est√° aqui para demonstrar a estrutura completa do ADK.
#
# üõ°Ô∏è Aula 02 - Intent Guardrail:
# Na pr√≥xima aula, implementaremos valida√ß√£o de inten√ß√£o do usu√°rio ANTES
# de chamar o modelo. Isso √© complementar aos safety_settings:
# - Intent Guardrail: Valida a pergunta do usu√°rio (prompt injection, etc.)
# - Safety Settings: Valida a resposta do modelo (conte√∫do prejudicial)
#
# üîó Aula 03 - Integra√ß√£o Real com Vertex AI:
# Quando substituirmos a simula√ß√£o por chamadas reais ao Vertex AI,
# estas configura√ß√µes ser√£o aplicadas automaticamente:
# ```python
# model = GenerativeModel(
#     model_name="gemini-1.5-pro-001",
#     safety_settings=safety_settings  # Carregadas deste arquivo
# )
# ```
#
# Estas configura√ß√µes s√£o aplicadas quando fazemos chamadas reais ao Vertex AI.
# Na demonstra√ß√£o atual (mock), estas configura√ß√µes n√£o s√£o utilizadas,
# mas est√£o aqui para refer√™ncia quando integrar com a API real.
#
# Categorias de Harm (Google Cloud Vertex AI):
# - HARM_CATEGORY_HARASSMENT: Conte√∫do de ass√©dio ou bullying
# - HARM_CATEGORY_HATE_SPEECH: Discurso de √≥dio
# - HARM_CATEGORY_SEXUALLY_EXPLICIT: Conte√∫do sexualmente expl√≠cito
# - HARM_CATEGORY_DANGEROUS_CONTENT: Conte√∫do perigoso (viol√™ncia, etc.)
#
# N√≠veis de Threshold:
# - BLOCK_NONE: N√£o bloqueia nada
# - BLOCK_ONLY_HIGH: Bloqueia apenas conte√∫do de alto risco
# - BLOCK_MEDIUM_AND_ABOVE: Bloqueia m√©dio e alto (recomendado)
# - BLOCK_LOW_AND_ABOVE: Bloqueia baixo, m√©dio e alto (mais restritivo)

safety_settings:
  # Bloqueia ass√©dio de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_HARASSMENT
    threshold: BLOCK_MEDIUM_AND_ABOVE

  # Bloqueia discurso de √≥dio de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_HATE_SPEECH
    threshold: BLOCK_MEDIUM_AND_ABOVE

  # Bloqueia conte√∫do sexualmente expl√≠cito de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
    threshold: BLOCK_MEDIUM_AND_ABOVE

  # Bloqueia conte√∫do perigoso de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_DANGEROUS_CONTENT
    threshold: BLOCK_MEDIUM_AND_ABOVE
