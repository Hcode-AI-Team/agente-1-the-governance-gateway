"""
Script de Demonstra√ß√£o - Governance Gateway - Aula 01
Simula o fluxo completo de roteamento e auditoria

üéØ Objetivo da Aula 01:
Demonstrar como criar um projeto padronizado com estrutura ADK e monitorar
custos de execu√ß√£o em tempo real. Este script simula o problema real:
scripts soltos em Python tornam-se inaudit√°veis e uso indiscriminado de
modelos caros (Gemini Pro) gera desperd√≠cio financeiro invis√≠vel.

üìö Estrutura ADK (Agent Development Kit) - Aula 01:
- prompts/: Templates versionados (audit_master.jinja2)
- config/: Configura√ß√µes (model_policy.yaml, safety_settings.yaml)
- tools/: Ferramentas do agente (ser√° usado nas aulas futuras)
- src/: C√≥digo Python modular

Por que separar prompts/, tools/ e config/?
1. Versionamento: Mudan√ßas em prompts podem ser rastreadas no Git
2. Auditoria: Configura√ß√µes em YAML s√£o audit√°veis e revis√°veis
3. Reutiliza√ß√£o: Templates podem ser compartilhados entre agentes
4. Desacoplamento: Mudan√ßas n√£o requerem alterar c√≥digo Python

Fluxo de Execu√ß√£o:
1. Carrega pol√≠tica de roteamento (YAML) - seguindo padr√£o ADK
2. Para cada cen√°rio de teste:
   a. Router decide qual modelo usar (FinOps: Flash vs Pro)
   b. Simula chamada ao LLM (mock - n√£o faz chamada real)
   c. Calcula custo estimado em tempo real
   d. Exibe resultados formatados no terminal

‚ö†Ô∏è IMPORTANTE - Simula√ß√£o vs Produ√ß√£o:
Esta √© uma demonstra√ß√£o educativa. Em produ√ß√£o, substitua simulate_llm_response()
por chamadas reais ao Vertex AI usando google-cloud-aiplatform.

üîÆ Pr√≥ximas Aulas:
- Aula 02: Adicionaremos Intent Guardrail (classifica√ß√£o de inten√ß√£o segura)
- Aula 03: Integra√ß√£o real com Vertex AI e output estruturado (JSON)
"""

import json
import logging
from pathlib import Path
from typing import Dict, Any
from jinja2 import Template, Environment, FileSystemLoader, TemplateNotFound
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.json import JSON

from .router import ModelRouter
from .telemetry import CostEstimator
from .models import AuditResponse
from .exceptions import TemplateNotFoundError
from .logger import setup_logging, get_logger

# Configurar logging
logger = get_logger(__name__)


def render_prompt_template(user_request: str, template_path: str = "prompts/audit_master.jinja2") -> str:
    """
    Carrega e processa o template Jinja2 do prompt de auditoria.
    
    üèóÔ∏è Estrutura ADK - Aula 01:
    Templates em prompts/ permitem:
    - Versionamento de prompts no Git
    - Reutiliza√ß√£o entre diferentes agentes
    - Mudan√ßas sem alterar c√≥digo Python
    - Auditoria de mudan√ßas em prompts
    
    üìö Engenharia de Prompt - Aula 02:
    Na pr√≥xima aula, este template ser√° expandido com:
    - Intent Guardrail (verifica√ß√£o de inten√ß√£o segura)
    - Chain-of-Thought para maior precis√£o
    - Configura√ß√£o de personas via YAML
    
    Usa Jinja2 para injetar vari√°veis dinamicamente no template.
    Isso permite versionamento de prompts e reutiliza√ß√£o.
    
    Args:
        user_request: Solicita√ß√£o do usu√°rio a ser injetada no template
        template_path: Caminho relativo para o arquivo de template
        
    Returns:
        Prompt processado com vari√°veis substitu√≠das
        
    Raises:
        FileNotFoundError: Se o template n√£o for encontrado
        TemplateError: Se houver erro no processamento do template
    """
    # Resolver caminho relativo √† raiz do projeto
    project_root = Path(__file__).parent.parent
    template_dir = project_root / "prompts"
    template_file = Path(template_path).name
    
    try:
        logger.debug(f"Renderizando template: {template_file}")
        # Configurar ambiente Jinja2 com FileSystemLoader
        env = Environment(
            loader=FileSystemLoader(str(template_dir)),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
        # Carregar e renderizar template
        template = env.get_template(template_file)
        rendered = template.render(user_request=user_request)
        logger.debug(f"Template renderizado com sucesso: {len(rendered)} caracteres")
        return rendered
    except TemplateNotFound as e:
        logger.error(f"Template n√£o encontrado: {template_file}")
        raise TemplateNotFoundError(
            f"Template n√£o encontrado: {template_dir / template_file}"
        ) from e
    except FileNotFoundError as e:
        logger.error(f"Diret√≥rio de templates n√£o encontrado: {template_dir}")
        raise TemplateNotFoundError(
            f"Template n√£o encontrado: {template_dir / template_file}"
        ) from e
    except Exception as e:
        logger.error(f"Erro ao processar template Jinja2: {e}", exc_info=True)
        raise ValueError(f"Erro ao processar template Jinja2: {e}") from e


def simulate_llm_response(model_name: str, user_request: str) -> Dict[str, Any]:
    """
    Simula a resposta do LLM sem fazer chamada real ao Vertex AI.
    
    ‚ö†Ô∏è IMPORTANTE - Aula 01 (Demonstra√ß√£o):
    Esta fun√ß√£o SIMULA uma resposta para focar nos conceitos de:
    - Roteamento de modelos (Router-Gateway pattern)
    - C√°lculo de custos (FinOps)
    - Estrutura ADK (separa√ß√£o de responsabilidades)
    
    üéØ Por que simula√ß√£o?
    - Evita complexidade de autentica√ß√£o ADC na primeira aula
    - Foca nos conceitos arquiteturais e FinOps
    - Permite demonstra√ß√£o sem custos reais
    
    üîÆ Aula 03 - Integra√ß√£o Real:
    Na Aula 03, substituiremos esta fun√ß√£o por:
    
    ```python
    from vertexai.preview.generative_models import GenerativeModel
    
    model = GenerativeModel(model_name)
    response = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",  # Aula 03: JSON estruturado
            "temperature": 0.1
        }
    )
    
    # Aula 03: Valida√ß√£o robusta com Pydantic
    return AuditResponse.model_validate_json(response.text)
    ```
    
    üõ°Ô∏è Aula 02 - Intent Guardrail:
    Na pr√≥xima aula, adicionaremos verifica√ß√£o de inten√ß√£o ANTES de chamar
    o modelo, bloqueando tentativas de prompt injection e engenharia social.
    
    A simula√ß√£o atual usa palavras-chave para determinar a resposta,
    simulando diferentes n√≠veis de risco e compliance.
    
    Args:
        model_name: Nome do modelo usado (ex: 'gemini-1.5-pro-001')
        user_request: Solicita√ß√£o do usu√°rio a ser analisada
        
    Returns:
        Dicion√°rio com a resposta simulada do auditor no formato:
        {
            "compliance_status": "APPROVED" | "REJECTED" | "REQUIRES_REVIEW",
            "risk_level": "LOW" | "MEDIUM" | "HIGH" | "CRITICAL",
            "audit_reasoning": "Texto explicativo"
        }
    """
    # ------------------------------------------------------------------------
    # L√≥gica de Simula√ß√£o por Palavras-chave
    # ------------------------------------------------------------------------
    # Em produ√ß√£o, esta l√≥gica seria substitu√≠da pela chamada real ao LLM
    # A simula√ß√£o usa palavras-chave para determinar o n√≠vel de risco
    request_lower = user_request.lower()
    
    # Ordem importa: verificar exclus√£o antes de outras opera√ß√µes
    if any(word in request_lower for word in ['exclus√£o', 'excluir', 'delete', 'remover', 'apagar']):
        compliance = "REJECTED"
        risk = "HIGH"
        reasoning = "Opera√ß√£o de exclus√£o de dados identificada. Rejeitada por violar pol√≠ticas de reten√ß√£o de dados."
    elif any(word in request_lower for word in ['transfer', 'transfer√™ncia', 'pix', 'pagamento']):
        compliance = "REQUIRES_REVIEW"
        risk = "MEDIUM"
        reasoning = "Opera√ß√£o financeira detectada. Requer revis√£o adicional conforme pol√≠tica de compliance."
    elif any(word in request_lower for word in ['consulta', 'saldo', 'extrato']):
        compliance = "APPROVED"
        risk = "LOW"
        reasoning = "Opera√ß√£o de consulta de baixo risco. Aprovada conforme pol√≠ticas de acesso."
    else:
        compliance = "APPROVED"
        risk = "LOW"
        reasoning = "Solicita√ß√£o gen√©rica analisada. Sem riscos identificados."
    
    # ------------------------------------------------------------------------
    # Simula√ß√£o de Diferen√ßa entre Modelos
    # ------------------------------------------------------------------------
    # Simula que o modelo Pro gera respostas mais detalhadas (mais tokens)
    # enquanto o Flash gera respostas mais concisas (menos tokens)
    # Isso afeta o c√°lculo de custos (mais tokens = maior custo)
    if 'pro' in model_name:
        # Resposta mais detalhada do Pro (simula an√°lise mais profunda)
        reasoning += " An√°lise detalhada realizada com modelo avan√ßado."
    else:
        # Resposta mais concisa do Flash (simula otimiza√ß√£o de custos)
        reasoning = reasoning[:100] + "."
    
    return {
        "compliance_status": compliance,
        "risk_level": risk,
        "audit_reasoning": reasoning
    }


def simulate_input_output(user_request: str, model_response: Dict[str, Any]) -> tuple[int, int]:
    """
    Simula o tamanho do input e output para c√°lculo de custos.
    
    üéØ Aula 01 - FinOps:
    Esta fun√ß√£o estima o tamanho do input/output para c√°lculo de custos.
    Em produ√ß√£o, estes valores viriam da API do Vertex AI que retorna
    informa√ß√µes sobre tokens usados na resposta.
    
    üìä M√©todo de Estimativa:
    1. Input: Template Jinja2 renderizado + user_request
    2. Output: JSON serializado da resposta
    
    üîÆ Aula 03 - Tokens Reais:
    Quando integrarmos com Vertex AI real, usaremos:
    ```python
    response.usage_metadata.prompt_token_count  # Input tokens
    response.usage_metadata.candidates_token_count  # Output tokens
    ```
    
    Por enquanto, simulamos calculando caracteres e convertendo para tokens
    usando tiktoken (m√©todo preciso) ou aproxima√ß√£o (fallback).
    
    Args:
        user_request: Solicita√ß√£o do usu√°rio
        model_response: Resposta do modelo (dicion√°rio)
        
    Returns:
        Tupla (input_chars, output_chars) - n√∫mero de caracteres em cada parte
    """
    # ------------------------------------------------------------------------
    # C√°lculo de Input (Prompt)
    # ------------------------------------------------------------------------
    # Simula o prompt completo que seria enviado ao modelo:
    # - Template do sistema (audit_master.jinja2) processado com Jinja2
    # - Solicita√ß√£o do usu√°rio injetada dinamicamente no template
    try:
        full_prompt = render_prompt_template(user_request)
        input_chars = len(full_prompt)
    except Exception as e:
        # Fallback: se houver erro no template, usa aproxima√ß√£o
        input_chars = len(user_request) + 500  # Aproxima√ß√£o do template
    
    # ------------------------------------------------------------------------
    # C√°lculo de Output (Resposta)
    # ------------------------------------------------------------------------
    # Simula a resposta JSON que o modelo retornaria
    # Em produ√ß√£o, este seria o texto real retornado pela API
    output_json = json.dumps(model_response, ensure_ascii=False, indent=2)
    output_chars = len(output_json)
    
    return input_chars, output_chars


def main():
    """
    Fun√ß√£o principal de demonstra√ß√£o.
    
    üéØ Aula 01 - FinOps em Tempo Real:
    Simula 3 requisi√ß√µes de diferentes departamentos para demonstrar:
    - Roteamento baseado em tier (platinum, standard, budget)
    - C√°lculo de custos em tempo real
    - Compara√ß√£o Flash vs Pro
    
    üìö Conex√£o com pr√≥ximas aulas:
    - Aula 02: Cada requisi√ß√£o ser√° validada por Intent Guardrail
    - Aula 03: Substituiremos simula√ß√£o por chamadas reais ao Vertex AI
    """
    # Configurar logging para a aplica√ß√£o
    setup_logging(level="INFO")
    logger.info("Iniciando Governance Gateway - Demonstra√ß√£o")
    
    console = Console()
    
    # T√≠tulo
    console.print("\n")
    console.print(
        Panel.fit(
            "[bold cyan]Governance Gateway[/bold cyan]\n"
            "[dim]Sistema de Roteamento de Modelos LLM - Padr√£o Router-Gateway[/dim]",
            border_style="cyan"
        )
    )
    console.print("\n")
    
    # ------------------------------------------------------------------------
    # Inicializa√ß√£o dos Componentes
    # ------------------------------------------------------------------------
    # Router: Carrega pol√≠tica YAML e decide qual modelo usar
    # CostEstimator: Carrega pre√ßos YAML e calcula custos
    try:
        logger.info("Inicializando componentes: ModelRouter e CostEstimator")
        router = ModelRouter()
        cost_estimator = CostEstimator()
        logger.info("Componentes inicializados com sucesso")
    except Exception as e:
        logger.error(f"Erro ao inicializar componentes: {e}", exc_info=True)
        console.print(f"[bold red]Erro ao inicializar componentes: {e}[/bold red]")
        return
    
    # ------------------------------------------------------------------------
    # Cen√°rios de Teste
    # ------------------------------------------------------------------------
    # Simula requisi√ß√µes de 3 departamentos diferentes para demonstrar
    # o roteamento baseado em tier e complexidade
    scenarios = [
        {
            "department": "legal_dept",
            "department_name": "Departamento Jur√≠dico",
            "user_request": "Preciso revisar o contrato de parceria com a empresa XYZ para verificar cl√°usulas de confidencialidade",
            "complexity": 0.8
        },
        {
            "department": "hr_dept",
            "department_name": "Recursos Humanos",
            "user_request": "Verificar saldo de f√©rias do funcion√°rio ID 12345",
            "complexity": 0.3
        },
        {
            "department": "it_ops",
            "department_name": "Opera√ß√µes de TI",
            "user_request": "Consultar logs de acesso do sistema de gest√£o",
            "complexity": 0.2
        }
    ]
    
    # ------------------------------------------------------------------------
    # Processamento de Cada Cen√°rio
    # ------------------------------------------------------------------------
    for idx, scenario in enumerate(scenarios, 1):
        console.print(f"\n[bold yellow]‚îÅ‚îÅ‚îÅ Cen√°rio {idx}: {scenario['department_name']} ‚îÅ‚îÅ‚îÅ[/bold yellow]\n")
        
        # --------------------------------------------------------------------
        # Passo 1: Roteamento (Decis√£o do Modelo)
        # --------------------------------------------------------------------
        # O router consulta a pol√≠tica YAML e decide qual modelo usar
        # baseado no tier do departamento e na complexidade da requisi√ß√£o
        try:
            logger.info(f"Processando cen√°rio {idx}: {scenario['department_name']}")
            selected_model = router.route_request(
                scenario['department'],
                scenario['complexity']
            )
            logger.debug(f"Modelo selecionado: {selected_model}")
        except Exception as e:
            logger.error(f"Erro no roteamento para {scenario['department']}: {e}", exc_info=True)
            console.print(f"[bold red]Erro no roteamento: {e}[/bold red]")
            continue
        
        # --------------------------------------------------------------------
        # Passo 2: Simula√ß√£o de Chamada ao LLM
        # --------------------------------------------------------------------
        # Em produ√ß√£o, aqui seria feita a chamada real ao Vertex AI
        # com o modelo selecionado e o prompt formatado
        mock_response = simulate_llm_response(
            selected_model,
            scenario['user_request']
        )
        
        # --------------------------------------------------------------------
        # Passo 3: C√°lculo de Custos (FinOps)
        # --------------------------------------------------------------------
        # Simula tamanho do input/output e calcula custo estimado
        # Em produ√ß√£o, os tokens viriam da resposta da API do Vertex AI
        input_chars, output_chars = simulate_input_output(
            scenario['user_request'],
            mock_response
        )
        
        try:
            estimated_cost = cost_estimator.calculate_cost(
                selected_model,
                input_chars,
                output_chars
            )
            logger.debug(f"Custo estimado: ${estimated_cost:.6f} USD")
        except Exception as e:
            logger.error(f"Erro no c√°lculo de custo: {e}", exc_info=True)
            console.print(f"[bold red]Erro no c√°lculo de custo: {e}[/bold red]")
            continue
        
        # --------------------------------------------------------------------
        # Passo 4: Exibi√ß√£o de Resultados
        # --------------------------------------------------------------------
        # Usa a biblioteca Rich para criar tabelas e pain√©is formatados
        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("Atributo", style="cyan", width=25)
        table.add_column("Valor", style="white")
        
        table.add_row("Departamento", scenario['department_name'])
        table.add_row("Complexidade", f"{scenario['complexity']:.2f}")
        table.add_row("Modelo Escolhido", f"[bold green]{selected_model}[/bold green]")
        table.add_row("Custo Estimado", f"[bold yellow]${estimated_cost:.6f} USD[/bold yellow]")
        table.add_row("Input (chars)", str(input_chars))
        table.add_row("Output (chars)", str(output_chars))
        
        console.print(table)
        
        # Exibir resposta do auditor em formato JSON formatado
        console.print("\n[bold]Resposta do Auditor:[/bold]")
        console.print(JSON(json.dumps(mock_response, ensure_ascii=False, indent=2)))
        
        console.print("\n")
    
    # ------------------------------------------------------------------------
    # Resumo Final
    # ------------------------------------------------------------------------
    logger.info("Demonstra√ß√£o conclu√≠da com sucesso")
    console.print(
        Panel.fit(
            "[bold green]‚úì Demonstra√ß√£o conclu√≠da com sucesso![/bold green]\n"
            "[dim]O sistema demonstrou o roteamento baseado em pol√≠tica YAML[/dim]",
            border_style="green"
        )
    )
    console.print("\n")


if __name__ == "__main__":
    main()
