# ============================================================================
# Configura√ß√µes de Seguran√ßa (Safety Settings) - Aula 03
# ============================================================================
# Define os n√≠veis de bloqueio para conte√∫do potencialmente prejudicial
# que o modelo pode gerar ou processar.
#
# üéØ Aula 03 - Defesa em Camadas:
# Safety Settings s√£o a camada de valida√ß√£o da SA√çDA (resposta do modelo).
# Complementam o Intent Guardrail que valida a ENTRADA (pergunta do usu√°rio):
#
# - Intent Guardrail: Valida a pergunta do usu√°rio (prompt injection, etc.)
# - Safety Settings: Valida a resposta do modelo (conte√∫do prejudicial)
#
# üõ°Ô∏è Como funciona:
# Quando fazemos chamadas reais ao Vertex AI, estas configura√ß√µes s√£o aplicadas
# automaticamente pelo SDK:
# ```python
# model = GenerativeModel(model_name)
# response = model.generate_content(
#     prompt,
#     safety_settings=safety_settings  # ‚Üê Carregadas deste arquivo
# )
# ```
#
# Se a resposta do modelo violar alguma categoria configurada, o Vertex AI:
# 1. Bloqueia a resposta (n√£o retorna o texto)
# 2. Define finish_reason = "SAFETY"
# 3. Retorna safety_ratings com detalhes
#
# üìä FinOps Note:
# Tokens s√£o cobrados MESMO quando a resposta √© bloqueada por safety.
# Por isso o Intent Guardrail √© importante: bloqueia ANTES de gastar tokens.
#
# Categorias de Harm (Google Cloud Vertex AI):
# - HARM_CATEGORY_HARASSMENT: Conte√∫do de ass√©dio ou bullying
# - HARM_CATEGORY_HATE_SPEECH: Discurso de √≥dio
# - HARM_CATEGORY_SEXUALLY_EXPLICIT: Conte√∫do sexualmente expl√≠cito
# - HARM_CATEGORY_DANGEROUS_CONTENT: Conte√∫do perigoso (viol√™ncia, etc.)
#
# N√≠veis de Threshold:
# - BLOCK_NONE: N√£o bloqueia nada
# - BLOCK_ONLY_HIGH: Bloqueia apenas conte√∫do de alto risco
# - BLOCK_MEDIUM_AND_ABOVE: Bloqueia m√©dio e alto (recomendado)
# - BLOCK_LOW_AND_ABOVE: Bloqueia baixo, m√©dio e alto (mais restritivo)

safety_settings:
  # Bloqueia ass√©dio de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_HARASSMENT
    threshold: BLOCK_MEDIUM_AND_ABOVE

  # Bloqueia discurso de √≥dio de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_HATE_SPEECH
    threshold: BLOCK_MEDIUM_AND_ABOVE

  # Bloqueia conte√∫do sexualmente expl√≠cito de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
    threshold: BLOCK_MEDIUM_AND_ABOVE

  # Bloqueia conte√∫do perigoso de n√≠vel m√©dio ou superior
  - category: HARM_CATEGORY_DANGEROUS_CONTENT
    threshold: BLOCK_MEDIUM_AND_ABOVE
