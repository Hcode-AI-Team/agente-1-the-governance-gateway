# Guia de Migra√ß√£o: Vertex AI com Gemini 2.5

Este documento descreve todas as mudan√ßas realizadas para migrar o projeto da simula√ß√£o mock para integra√ß√£o real com o Vertex AI usando os modelos Gemini 2.5 Pro e Gemini 2.5 Flash.

## üìã √çndice

- [Vis√£o Geral das Mudan√ßas](#vis√£o-geral-das-mudan√ßas)
- [Passo a Passo da Implementa√ß√£o](#passo-a-passo-da-implementa√ß√£o)
- [Como Usar](#como-usar)
- [Configura√ß√£o do GCP](#configura√ß√£o-do-gcp)
- [Toggle Mock/Produ√ß√£o](#toggle-mockprodu√ß√£o)
- [Diferen√ßas entre Modos](#diferen√ßas-entre-modos)
- [Troubleshooting](#troubleshooting)

---

## Vis√£o Geral das Mudan√ßas

### O que mudou?

1. **Modelos atualizados**: Gemini 1.5 ‚Üí Gemini 2.5
2. **Integra√ß√£o real com Vertex AI**: Adicionada fun√ß√£o `call_vertex_ai()` que faz chamadas reais √† API
3. **Toggle Mock/Produ√ß√£o**: Vari√°vel `USE_MOCK` permite alternar entre simula√ß√£o e API real
4. **Tokens reais**: Novo m√©todo `calculate_cost_from_tokens()` usa tokens exatos da API
5. **Safety Settings**: Configura√ß√µes de seguran√ßa agora s√£o aplicadas nas chamadas reais
6. **Autentica√ß√£o ADC**: Suporte para Application Default Credentials do Google Cloud

### Arquitetura Atualizada

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   main.py       ‚îÇ
‚îÇ  (orchestrator) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ USE_MOCK?‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ TRUE          ‚îÇ FALSE       ‚îÇ
    ‚îÇ simula√ß√£o     ‚îÇ produ√ß√£o    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ simulate ‚îÇ    ‚îÇ call_vertex_ai()‚îÇ
    ‚îÇ _llm_    ‚îÇ    ‚îÇ                 ‚îÇ
    ‚îÇ response ‚îÇ    ‚îÇ GenerativeModel ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                ‚îÇ
         ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ           ‚îÇ usage_metadata‚îÇ
         ‚îÇ           ‚îÇ (tokens reais)‚îÇ
         ‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê
    ‚îÇ   CostEstimator        ‚îÇ
    ‚îÇ - calculate_cost()      ‚îÇ
    ‚îÇ - calculate_cost_from_  ‚îÇ
    ‚îÇ   tokens() ‚≠ê NOVO      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Passo a Passo da Implementa√ß√£o

### Passo 0: Autentica√ß√£o no Google Cloud (Pr√©-requisito)

Antes de usar o modo produ√ß√£o, configure a autentica√ß√£o:

```bash
# 1. Instalar o Google Cloud CLI
# Download em: https://cloud.google.com/sdk/docs/install

# 2. Fazer login no GCP
gcloud auth login

# 3. Configurar Application Default Credentials (ADC)
gcloud auth application-default login

# 4. Definir o projeto padr√£o
gcloud config set project SEU_PROJECT_ID
```

**Importante**: A autentica√ß√£o ADC √© necess√°ria APENAS para o modo produ√ß√£o (USE_MOCK=false).

### Passo 1: Arquivo `.env`

Criado arquivo `.env` na raiz do projeto:

```env
# Google Cloud Project ID
GOOGLE_CLOUD_PROJECT=seu-project-id-aqui

# Regi√£o do Vertex AI (ex: us-central1, us-east1)
GOOGLE_CLOUD_LOCATION=us-east1

# Toggle: true = simula√ß√£o, false = API real
USE_MOCK=true
```

**Seguran√ßa**: O arquivo `.env` foi adicionado ao `.gitignore` e n√£o deve ser versionado.

### Passo 2: Depend√™ncias Atualizadas

Arquivo `requirements.txt` foi atualizado:

```txt
google-cloud-aiplatform>=1.74.0   # Suporte Gemini 2.5
python-dotenv>=1.0.0               # Carregar vari√°veis do .env
```

Instalar com:

```bash
pip install -r requirements.txt
```

### Passo 3: Modelos Atualizados

#### `config/model_policy.yaml`

Nomes dos modelos atualizados:

```yaml
departments:
  legal_dept:
    model: gemini-2.5-pro      # Era: gemini-1.5-pro-001
  
  it_ops:
    model: gemini-2.5-flash    # Era: gemini-1.5-flash-001

pricing:
  gemini-2.5-pro:
    input_per_1k_tokens: 0.00125
    output_per_1k_tokens: 0.01000
  
  gemini-2.5-flash:
    input_per_1k_tokens: 0.000150
    output_per_1k_tokens: 0.000600
```

### Passo 4: Valida√ß√£o Pydantic

#### `src/models.py`

Lista de modelos v√°lidos atualizada:

```python
valid_models = ['gemini-2.5-pro', 'gemini-2.5-flash']
```

### Passo 5: Router Atualizado

#### `src/router.py`

Nomes hardcoded dos modelos atualizados em 4 locais:

- Tier platinum: `'gemini-2.5-pro'`
- Tier budget: `'gemini-2.5-flash'`
- Tier standard (baixa complexidade): `'gemini-2.5-flash'`
- Tier standard (alta complexidade): `'gemini-2.5-pro'`

### Passo 6: Integra√ß√£o com Vertex AI

#### `src/main.py`

**Novos imports**:

```python
import os
import yaml
from dotenv import load_dotenv
import vertexai
from vertexai.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold
```

**Nova fun√ß√£o `load_safety_settings()`**:

Carrega configura√ß√µes do `config/safety_settings.yaml` e converte para enums do Vertex AI.

**Nova fun√ß√£o `call_vertex_ai()`**:

```python
def call_vertex_ai(model_name: str, prompt: str, safety_settings: Dict) -> Tuple[Dict, int, int]:
    """
    Faz chamada real ao Vertex AI.
    
    Returns:
        Tupla (resposta_dict, input_tokens, output_tokens)
    """
    model = GenerativeModel(model_name)
    
    response = model.generate_content(
        prompt,
        generation_config={
            "response_mime_type": "application/json",
            "temperature": 0.1
        },
        safety_settings=safety_settings
    )
    
    # Extrair tokens REAIS
    input_tokens = response.usage_metadata.prompt_token_count
    output_tokens = response.usage_metadata.candidates_token_count
    
    # Validar JSON com Pydantic
    audit_response = AuditResponse.model_validate_json(response.text)
    
    return audit_response.model_dump(), input_tokens, output_tokens
```

**Fun√ß√£o `main()` atualizada**:

- Inicializa Vertex AI se `USE_MOCK=false`
- Carrega safety settings
- Toggle para escolher entre simula√ß√£o e API real
- Exibe tokens reais quando em modo produ√ß√£o

### Passo 7: C√°lculo de Custos com Tokens Reais

#### `src/telemetry.py`

**Novo m√©todo `calculate_cost_from_tokens()`**:

```python
def calculate_cost_from_tokens(
    self,
    model_name: str,
    input_tokens: int,
    output_tokens: int
) -> float:
    """
    Calcula custo usando tokens REAIS da API (100% preciso).
    """
    model_pricing = self.pricing[model_name]
    input_cost = (input_tokens / 1000.0) * model_pricing.input_per_1k_tokens
    output_cost = (output_tokens / 1000.0) * model_pricing.output_per_1k_tokens
    return round(input_cost + output_cost, 6)
```

### Passo 8: Safety Settings

As configura√ß√µes de `config/safety_settings.yaml` agora s√£o:

- Carregadas pela fun√ß√£o `load_safety_settings()`
- Convertidas para enums do Vertex AI
- Aplicadas na chamada ao `GenerativeModel.generate_content()`

### Passo 9: Testes Atualizados

Todos os testes foram atualizados:

- **`tests/test_router.py`**: Nomes de modelos atualizados em 9 asserts
- **`tests/test_telemetry.py`**: Nomes atualizados + 5 novos testes para `calculate_cost_from_tokens()`
- **`tests/test_models.py`**: Nomes atualizados + valida√ß√£o de pricing

**Novos testes adicionados**:

- `test_calculate_cost_from_tokens_pro()`: Testa c√°lculo com tokens reais para Pro
- `test_calculate_cost_from_tokens_flash()`: Testa c√°lculo com tokens reais para Flash
- `test_calculate_cost_from_tokens_invalid_model()`: Testa erro com modelo inv√°lido
- `test_calculate_cost_from_tokens_zero_values()`: Testa edge case com tokens zero
- `test_calculate_cost_from_tokens_precision()`: Testa precis√£o de 6 casas decimais

---

## Como Usar

### Modo Simula√ß√£o (Padr√£o)

```bash
# 1. Configure o .env (ou deixe o padr√£o)
echo "USE_MOCK=true" > .env

# 2. Execute
python main.py
```

**Sem autentica√ß√£o necess√°ria. Sem custos.**

### Modo Produ√ß√£o (API Real)

```bash
# 1. Configure autentica√ß√£o (apenas primeira vez)
gcloud auth application-default login

# 2. Configure o .env
cat > .env << EOF
GOOGLE_CLOUD_PROJECT=seu-project-id
GOOGLE_CLOUD_LOCATION=us-east1
USE_MOCK=false
EOF

# 3. Execute
python main.py
```

**‚ö†Ô∏è ATEN√á√ÉO: Gera custos reais no GCP!**

---

## Configura√ß√£o do GCP

### 1. Criar Projeto no GCP

```bash
gcloud projects create fiap-bv-ia-2025 --name="FIAP BV IA 2025"
gcloud config set project fiap-bv-ia-2025
```

### 2. Habilitar APIs Necess√°rias

```bash
gcloud services enable aiplatform.googleapis.com
```

### 3. Configurar Billing

O projeto precisa ter billing habilitado para usar o Vertex AI:

1. Acesse: https://console.cloud.google.com/billing
2. Vincule um billing account ao projeto

### 4. Permiss√µes Necess√°rias

Sua conta precisa das seguintes roles:

- `roles/aiplatform.user` - Usar o Vertex AI
- `roles/serviceusage.serviceUsageConsumer` - Consumir APIs

```bash
gcloud projects add-iam-policy-binding fiap-bv-ia-2025 \
    --member="user:seu-email@gmail.com" \
    --role="roles/aiplatform.user"
```

---

## Toggle Mock/Produ√ß√£o

### Como funciona o toggle?

A vari√°vel `USE_MOCK` no arquivo `.env` controla o comportamento:

```python
USE_MOCK = os.getenv("USE_MOCK", "true").lower() == "true"

if USE_MOCK:
    # Usa simulate_llm_response() - sem custos
    response_data = simulate_llm_response(model_name, user_request)
else:
    # Usa call_vertex_ai() - API real com custos
    response_data, input_tokens, output_tokens = call_vertex_ai(model_name, prompt)
```

### Quando usar cada modo?

| Modo       | Quando usar                                  | Requer Auth | Gera Custos |
| ---------- | -------------------------------------------- | ----------- | ----------- |
| Simula√ß√£o  | Desenvolvimento, testes, aulas, demos        | ‚ùå N√£o      | ‚ùå N√£o      |
| Produ√ß√£o   | Produ√ß√£o, valida√ß√£o real, benchmark de custos| ‚úÖ Sim      | ‚úÖ Sim      |

---

## Diferen√ßas entre Modos

### Simula√ß√£o (USE_MOCK=true)

**Vantagens**:
- ‚úÖ Sem autentica√ß√£o necess√°ria
- ‚úÖ Sem custos
- ‚úÖ R√°pido (sem lat√™ncia de rede)
- ‚úÖ Determin√≠stico (sempre mesma resposta)

**Limita√ß√µes**:
- ‚ùå Respostas baseadas em keywords (n√£o usa IA real)
- ‚ùå Tokens estimados (aproxima√ß√£o com tiktoken)
- ‚ùå N√£o valida integra√ß√£o real com Vertex AI

**Casos de uso**:
- Desenvolvimento local
- Testes unit√°rios
- Demonstra√ß√µes em aula
- CI/CD pipeline

### Produ√ß√£o (USE_MOCK=false)

**Vantagens**:
- ‚úÖ Usa IA real (Gemini 2.5 Pro/Flash)
- ‚úÖ Respostas inteligentes e contextuais
- ‚úÖ Tokens EXATOS da API (100% preciso)
- ‚úÖ Valida√ß√£o JSON estruturado
- ‚úÖ Safety settings aplicados

**Limita√ß√µes**:
- ‚ùå Requer autentica√ß√£o ADC
- ‚ùå Gera custos reais no GCP
- ‚ùå Lat√™ncia de rede (500-2000ms por chamada)
- ‚ùå Sujeito a rate limits da API

**Casos de uso**:
- Valida√ß√£o de integra√ß√£o
- Testes de aceita√ß√£o
- Benchmark de custos
- Produ√ß√£o

---

## Troubleshooting

### Erro: "Vertex AI SDK n√£o instalado"

**Causa**: Biblioteca `google-cloud-aiplatform` n√£o instalada.

**Solu√ß√£o**:
```bash
pip install google-cloud-aiplatform>=1.74.0
```

### Erro: "GOOGLE_CLOUD_PROJECT n√£o definido"

**Causa**: Arquivo `.env` n√£o configurado ou vari√°vel ausente.

**Solu√ß√£o**:
```bash
echo "GOOGLE_CLOUD_PROJECT=seu-project-id" >> .env
```

### Erro: "Could not automatically determine credentials"

**Causa**: Application Default Credentials n√£o configuradas.

**Solu√ß√£o**:
```bash
gcloud auth application-default login
```

### Erro: "Permission denied on resource project"

**Causa**: Conta n√£o tem permiss√µes no projeto GCP.

**Solu√ß√£o**:
```bash
gcloud projects add-iam-policy-binding SEU_PROJECT_ID \
    --member="user:seu-email@gmail.com" \
    --role="roles/aiplatform.user"
```

### Erro: "API [aiplatform.googleapis.com] not enabled"

**Causa**: API do Vertex AI n√£o habilitada no projeto.

**Solu√ß√£o**:
```bash
gcloud services enable aiplatform.googleapis.com
```

### Erro: "Modelo n√£o encontrado na pol√≠tica"

**Causa**: Nome do modelo no YAML n√£o corresponde ao esperado.

**Solu√ß√£o**: Verifique se `config/model_policy.yaml` usa:
- `gemini-2.5-pro` (n√£o `gemini-1.5-pro-001`)
- `gemini-2.5-flash` (n√£o `gemini-1.5-flash-001`)

### Performance: Chamadas muito lentas

**Causa**: Lat√™ncia de rede para API do Vertex AI.

**Solu√ß√µes**:
1. Use regi√£o `GOOGLE_CLOUD_LOCATION` mais pr√≥xima
2. Configure timeout adequado
3. Considere caching de respostas
4. Use batch processing quando poss√≠vel

---

## Compara√ß√£o de Custos (Gemini 2.5)

### Pricing (valores de refer√™ncia)

| Modelo            | Input ($/1k tokens) | Output ($/1k tokens) | Uso recomendado       |
| ----------------- | ------------------- | -------------------- | --------------------- |
| gemini-2.5-pro    | $0.00125            | $0.01000             | Tarefas complexas     |
| gemini-2.5-flash  | $0.00015            | $0.00060             | Tarefas simples       |

### Exemplo de Custos

**Cen√°rio**: 1000 tokens input, 500 tokens output

```
Pro:
  Input:  (1000/1000) * $0.00125 = $0.00125
  Output: (500/1000)  * $0.01000 = $0.00500
  Total:  $0.00625

Flash:
  Input:  (1000/1000) * $0.00015 = $0.00015
  Output: (500/1000)  * $0.00060 = $0.00030
  Total:  $0.00045

Economia: $0.00625 - $0.00045 = $0.00580 (92.8% mais barato!)
```

### Calculadora de ROI

Para 1.000.000 de requisi√ß√µes/m√™s:

```
Se usar apenas Pro:
  1M requisi√ß√µes * $0.00625 = $6,250/m√™s

Se usar Router-Gateway (50% Flash, 50% Pro):
  500k * $0.00045 + 500k * $0.00625 = $3,350/m√™s
  
Economia anual: $34,800
```

---

## Checklist de Valida√ß√£o

Antes de usar em produ√ß√£o, valide:

- [ ] Autentica√ß√£o ADC configurada
- [ ] Vari√°vel `GOOGLE_CLOUD_PROJECT` correta
- [ ] API `aiplatform.googleapis.com` habilitada
- [ ] Permiss√µes IAM configuradas
- [ ] Billing account vinculado ao projeto
- [ ] Testes passando (`pytest tests/`)
- [ ] Arquivo `.env` configurado
- [ ] Safety settings revisadas
- [ ] Pol√≠tica de roteamento ajustada
- [ ] Monitoramento de custos configurado

---

## Pr√≥ximos Passos

### Melhorias Sugeridas

1. **Caching de Respostas**: Implementar Redis para cache de respostas frequentes
2. **Rate Limiting**: Adicionar controle de taxa para evitar rate limits
3. **Async/Await**: Refatorar para chamadas ass√≠ncronas (maior throughput)
4. **Batch Processing**: Processar m√∫ltiplas requisi√ß√µes em paralelo
5. **Monitoramento**: Integrar com Cloud Monitoring para dashboards
6. **Alertas**: Configurar alertas de custo no GCP
7. **Retry Logic**: Implementar retry com backoff exponencial
8. **Circuit Breaker**: Adicionar circuit breaker para failover

### Aulas Futuras

- **Aula 02**: Intent Guardrail (valida√ß√£o de seguran√ßa)
- **Aula 03**: Output estruturado e valida√ß√£o avan√ßada
- **Aula 04**: Integra√ß√£o com ferramentas (Function Calling)
- **Aula 05**: Deployment em produ√ß√£o (Cloud Run)

---

## Refer√™ncias

- [Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs)
- [Gemini API Reference](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini)
- [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)
- [Application Default Credentials](https://cloud.google.com/docs/authentication/application-default-credentials)
- [Safety Settings](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai)

---

**Vers√£o**: 2.0 (Gemini 2.5)  
**Data**: 2026-02-06  
**Status**: ‚úÖ Implementa√ß√£o completa
